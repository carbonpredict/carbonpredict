{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for modelling\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare original source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textile-v1.0.0-1.csv textile-v1.0.0-3.csv textile-v1.0.0-5.csv\n",
      "textile-v1.0.0-2.csv textile-v1.0.0-4.csv\n"
     ]
    }
   ],
   "source": [
    "# Local data directory\n",
    "path = './tdata/'\n",
    "!ls  tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_data(path, weight = 'd'):\n",
    "    \"\"\"\n",
    "    Read and concatenate the source data from the csv files to a pandas dataframe in local folder.\n",
    "    The weight parameter has the following values: \n",
    "        - 'd' (default), drops the weight feature (column) and does not use it in training,\n",
    "        - 'm', drops the samples (rows) from training where the weight feature is missing\n",
    "        - 'a', uses also the samples (rows) where weigth feature is missing\n",
    "    \"\"\"\n",
    "    print('Starting to open data from csv-files')\n",
    "    content = sorted(filter(lambda x: x.endswith(\".csv\"), os.listdir(path)))\n",
    "    print('Data in content, starting to concatenate data')\n",
    "    X = pd.concat((pd.read_csv(f) for f in content))\n",
    "    print('Data loaded to pandas dataframe')\n",
    "    \n",
    "    # Drop empty columns\n",
    "    X = X.drop(['label','unspsc_code'],axis=1)\n",
    "    print('Empty columns dropped')\n",
    "\n",
    "    X = X[~X[\"co2_total\"].isna()]\n",
    "    print('Rows with no c02_total value dropped')\n",
    "    \n",
    "    if weight == 'd':\n",
    "        X = X.drop(['weight'], axis = 1)\n",
    "        print('Weight column dropped from training data')\n",
    "        print('Shape of X =', X.shape)\n",
    "    elif weight == 'm':\n",
    "        X = X[~X[\"weight\"].isna()]\n",
    "        print('\\n Rows with weight value but samples without weight dropped')\n",
    "        print('Shape of X =', X.shape)\n",
    "    elif weight == 'a':\n",
    "        print('\\n Rows with weight and all rows but missing weght values set to zero')\n",
    "        print('Shape of X =', X.shape)\n",
    "    else:\n",
    "        print(\"Error: Wrong weight value given. Possible values 'd', 'e' and 'a'\")\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    print('dataframe ready')\n",
    "    y = X['co2_total'].copy()\n",
    "    X = X.drop('co2_total', axis=1)\n",
    "\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    # Drop empty features (dataset v. 1.0.0): unspsc_code, label \n",
    "    print('Start preprocessing data')\n",
    "    \n",
    "    # Set missing fiber type percentages to zero\n",
    "    values ={'ftp_acrylic': 0, 'ftp_cotton': 0, 'ftp_elastane': 0, 'ftp_linen': 0, 'ftp_other': 0, 'ftp_polyamide': 0, 'ftp_polyester': 0, 'ftp_polypropylene': 0, 'ftp_silk': 0, 'ftp_viscose': 0, 'ftp_wool': 0}\n",
    "    X = X.fillna(value=values)\n",
    "    print('Null fiber percentages changed to zero')\n",
    "    \n",
    "    # Fill categorical nan values for gender and season features with mode values. May need to be updated with new training data\n",
    "    X['gender'] = X.fillna(X['gender'].value_counts().index[0])\n",
    "    X['season'] = X.fillna(X['season'].value_counts().index[0])\n",
    "    print('Categorial values with null replaced with mode values')\n",
    "    \n",
    "    # Convert the categoricals into a one-hot vector of dummy binary variables\n",
    "    X = pd.get_dummies(X,columns=['category-1', 'category-2', 'category-3', 'brand', 'colour', 'fabric_type', 'gender', 'season','made_in','size'], prefix = ['category-1', 'category-2', 'category-3', 'brand', 'colour', 'fabric_type',  'gender', 'season','made_in','size'])\n",
    "    print('Categorial values changed to dummy one-hot vectors')\n",
    "    \n",
    "    # If still some null values, change them to zero. At least the weight feature (column) has many null values. \n",
    "    X = X.fillna(0)\n",
    "    print('Rest of the null values set to zero')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear(path, test_size=0.2, weight = 'd'):\n",
    "    print('Start training linear')\n",
    "    X, y = load_source_data(path, weight=weight)\n",
    "    print('Data loaded')\n",
    "    X = preprocess(X)\n",
    "    print('Data preprocessed')\n",
    "    X = X.to_numpy(dtype='float32')\n",
    "    y = y.to_numpy(dtype='float32')\n",
    "    print('Formatted to numpy')\n",
    "    \n",
    "    # Split training data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    print('Split to testing data')\n",
    "\n",
    "    # Initialize and train linear model\n",
    "    model_lr = LinearRegression(fit_intercept=True)\n",
    "    print('Model initialized')\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    print('Model trained')\n",
    "    \n",
    "    # Make predictions based on the model\n",
    "    y_fit = model_lr.predict(X_test)\n",
    "    print('Make predictions')\n",
    "    \n",
    "    # Evaluate model\n",
    "    rmse_score = mean_squared_error(y_test, y_fit, squared=False)\n",
    "    R2_score = r2_score(y_test, y_fit)\n",
    "    print('Model evaluated')\n",
    "\n",
    "\n",
    "    return model_lr, rmse_score, R2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textile-v1.0.0-1.csv textile-v1.0.0-3.csv textile-v1.0.0-5.csv\n",
      "textile-v1.0.0-2.csv textile-v1.0.0-4.csv\n"
     ]
    }
   ],
   "source": [
    "# Local data directory\n",
    "path = './tdata/'\n",
    "!ls  tdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = load_source_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xp = preprocess(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model without weight feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training linear\n",
      "Starting to open data from csv-files\n",
      "Data in content, starting to concatenate data\n",
      "Data loaded to pandas dataframe\n",
      "Empty columns dropped\n",
      "Rows with no c02_total value dropped\n",
      "Weight column dropped from training data\n",
      "Shape of X = (1699515, 22)\n",
      "\n",
      "dataframe ready\n",
      "Data loaded\n",
      "Start preprocessing data\n",
      "Null fiber percentages changed to zero\n",
      "Categorial values with null replaced with mode values\n",
      "Categorial values changed to dummy one-hot vectors\n",
      "Rest of the null values set to zero\n",
      "Data preprocessed\n",
      "Formatted to numpy\n",
      "Split to testing data\n",
      "Model initialized\n",
      "Model trained\n",
      "Make predictions\n",
      "Model evaluated\n"
     ]
    }
   ],
   "source": [
    "model_lr, rmse_score, r2_score = train_linear(path, weight='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model stats without weight feature:\n",
      "RMSE Score: 16.816357\n",
      "R2 Score: 0.6298162778863827\n"
     ]
    }
   ],
   "source": [
    "print('Linear model stats without weight feature:')\n",
    "print('RMSE Score:', rmse_score)\n",
    "print('R2 Score:', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with weight feature but samples (rows) with empty weight value droppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training linear\n",
      "Starting to open data from csv-files\n",
      "Data in content, starting to concatenate data\n",
      "Data loaded to pandas dataframe\n",
      "Empty columns dropped\n",
      "Rows with no c02_total value dropped\n",
      "\n",
      " Rows with weight value but samples without weight dropped\n",
      "Shape of X = (680256, 23)\n",
      "\n",
      "dataframe ready\n",
      "Data loaded\n",
      "Start preprocessing data\n",
      "Null fiber percentages changed to zero\n",
      "Categorial values with null replaced with mode values\n",
      "Categorial values changed to dummy one-hot vectors\n",
      "Rest of the null values set to zero\n",
      "Data preprocessed\n",
      "Formatted to numpy\n",
      "Split to testing data\n",
      "Model initialized\n",
      "Model trained\n",
      "Make predictions\n",
      "Model evaluated\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "model_lr, rmse_score_nw, r2_score_nw = train_linear(path, weight='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model stats with weight feature and samples (rows) missing weight feature dropped:\n",
      "RMSE Score: 9.889889\n",
      "R2 Score: 0.873564499590352\n"
     ]
    }
   ],
   "source": [
    "print('Linear model stats with weight feature and samples (rows) missing weight feature dropped:')\n",
    "print('RMSE Score:', rmse_score_nw)\n",
    "print('R2 Score:', r2_score_nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with weight feature and samples (rows) with empty weight value set to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training linear\n",
      "Starting to open data from csv-files\n",
      "Data in content, starting to concatenate data\n",
      "Data loaded to pandas dataframe\n",
      "Empty columns dropped\n",
      "Rows with no c02_total value dropped\n",
      "\n",
      " Rows with weight and all rows but missing weght values set to zero\n",
      "Shape of X = (1699515, 23)\n",
      "\n",
      "dataframe ready\n",
      "Data loaded\n",
      "Start preprocessing data\n",
      "Null fiber percentages changed to zero\n",
      "Categorial values with null replaced with mode values\n",
      "Categorial values changed to dummy one-hot vectors\n",
      "Rest of the null values set to zero\n",
      "Data preprocessed\n",
      "Formatted to numpy\n",
      "Split to testing data\n",
      "Model initialized\n",
      "Model trained\n",
      "Make predictions\n",
      "Model evaluated\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "model_lr, rmse_score_a, r2_score_a = train_linear(path, weight='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model stats with weight feature and missing weight values set to zero\n",
      "RMSE Score: 16.178186\n",
      "R2 Score: 0.6573795656653727\n"
     ]
    }
   ],
   "source": [
    "print('Linear model stats with weight feature and missing weight values set to zero')\n",
    "print('RMSE Score:', rmse_score_a)\n",
    "print('R2 Score:', r2_score_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
