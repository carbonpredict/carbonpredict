{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data' # Need to have the data as CSV files in this path\n",
    "#DATA_PATH = '../data/mini' # Need to have the data as CSV files in this path\n",
    "\n",
    "TEST_FILE = '../data/test/test.csv' # Need to have the data as CSV files in this path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_data(path):\n",
    "    content = sorted(filter(lambda x: x.endswith(\".csv\"), os.listdir(path)))\n",
    "    df = pd.concat((pd.read_csv(f'{path}/{f}') for f in content))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, drop_weight_na=True):\n",
    "    # Drop empty features (dataset v. 1.0.0): unspsc_code, label \n",
    "    df = df.drop(['label', 'unspsc_code'], axis=1)\n",
    "\n",
    "    # Drop co2_total (target)\n",
    "    df = df.drop(['co2_total'], axis=1)\n",
    "\n",
    "    if (drop_weight_na):\n",
    "        df = df[~df[\"weight\"].isna()]\n",
    "        \n",
    "    # Use unordered caterogies for several columns. List category values to support use cases when some\n",
    "    # values are absent from a batch of source data.\n",
    "    brand_types = CategoricalDtype(categories=[\"b0\", \"b1\", \"b10\", \"b100\", \"b101\", \"b102\", \"b103\", \"b104\", \"b105\", \"b106\", \"b107\", \"b108\", \"b109\", \"b11\", \"b110\", \"b111\", \"b112\", \"b113\", \"b114\", \"b115\", \"b116\", \"b117\", \"b118\", \"b119\", \"b12\", \"b120\", \"b121\", \"b122\", \"b123\", \"b124\", \"b125\", \"b126\", \"b127\", \"b128\", \"b129\", \"b13\", \"b130\", \"b131\", \"b132\", \"b133\", \"b134\", \"b135\", \"b136\", \"b137\", \"b138\", \"b139\", \"b14\", \"b140\", \"b141\", \"b142\", \"b143\", \"b144\", \"b145\", \"b146\", \"b147\", \"b148\", \"b149\", \"b15\", \"b16\", \"b17\", \"b18\", \"b19\", \"b2\", \"b20\", \"b21\", \"b22\", \"b23\", \"b24\", \"b25\", \"b26\", \"b27\", \"b28\", \"b29\", \"b3\", \"b30\", \"b31\", \"b32\", \"b33\", \"b34\", \"b35\", \"b36\", \"b37\", \"b38\", \"b39\", \"b4\", \"b40\", \"b41\", \"b42\", \"b43\", \"b44\", \"b45\", \"b46\", \"b47\", \"b48\", \"b49\", \"b5\", \"b50\", \"b51\", \"b52\", \"b53\", \"b54\", \"b55\", \"b56\", \"b57\", \"b58\", \"b59\", \"b6\", \"b60\", \"b61\", \"b62\", \"b63\", \"b64\", \"b65\", \"b66\", \"b67\", \"b68\", \"b69\", \"b7\", \"b70\", \"b71\", \"b72\", \"b73\", \"b74\", \"b75\", \"b76\", \"b77\", \"b78\", \"b79\", \"b8\", \"b80\", \"b81\", \"b82\", \"b83\", \"b84\", \"b85\", \"b86\", \"b87\", \"b88\", \"b89\", \"b9\", \"b90\", \"b91\", \"b92\", \"b93\", \"b94\", \"b95\", \"b96\", \"b97\", \"b98\", \"b99\"], ordered=False)\n",
    "    df[\"brand\"] = df[\"brand\"].astype(brand_types)\n",
    "    cat1_types =  CategoricalDtype(categories=[\"baby\", \"clothing\", \"home\", \"kidswear\", \"menswear\", \"womenswear\"], ordered=False)\n",
    "    df[\"category-1\"] = df[\"category-1\"].astype(cat1_types)\n",
    "    cat2_types = CategoricalDtype(categories=[\"home\", \"footwear\", \"nightwear\", \"thermals\", \"outerwear\", \"accessory\", \"uniform\", \"suit\", \"swimwear\", \"headgear\", \"sportswear\", \"costume\", \"clothing\", \"undergarments\", \"baby\", \"dress\", \"beachwear\", \"men-undergarments\", \"hosiery\", \"women-beachwear\", \"women-undergarments\", \"women-sportswear\"], ordered=False)\n",
    "    df[\"category-2\"] = df[\"category-2\"].astype(cat2_types)\n",
    "    cat3_types = CategoricalDtype(categories=[\"backpack\", \"bikin\", \"body\", \"boxer-brief\", \"bra\", \"brief\", \"briefs\", \"cap\", \"coats\", \"costume\", \"curtain\", \"dress\", \"evening-dress\", \"fancy-dress\", \"flat-cap\", \"gloves\", \"hat\", \"hoodie\", \"jacket\", \"jean-shorts\", \"jeans\", \"jersey\", \"knit-cap\", \"knitwear\", \"long-sleeved-top\", \"mat\", \"overalls\", \"panties\", \"pants\", \"pillow\", \"pyjama\", \"scarf\", \"sheets\", \"shorts\", \"skirts\", \"snow-suit\", \"socks\", \"sport-bra\", \"stockings\", \"swimsuit\", \"T-shirt\", \"tie\", \"tights\", \"top\", \"towel\", \"trousers\", \"underpants\", \"wedding-dress\"], ordered=False)\n",
    "    df[\"category-3\"] = df[\"category-3\"].astype(cat3_types)\n",
    "    colour_types = CategoricalDtype(categories=[\"Ivory\", \"amber\", \"aquamarine\", \"black\", \"blue\", \"blue gray\", \"bondi blue\", \"brown\", \"colourful\", \"dark green\", \"dark grey\", \"gold\", \"golden\", \"gray\", \"green\", \"grey\", \"indigo\", \"light brown\", \"light grey\", \"lime\", \"maroon\", \"metal\", \"mosaic\", \"mustard\", \"natural\", \"navy\", \"neon\", \"orange\", \"peach\", \"pink\", \"purple\", \"red\", \"silver\", \"teal\", \"turquoise\", \"unbleached\", \"unknown\", \"violet\", \"wheat\", \"white\", \"yellow\"], ordered=False)\n",
    "    df[\"colour\"] = df[\"colour\"].astype(colour_types)\n",
    "    fabric_type_types = CategoricalDtype(categories=[\"K\", \"W\"], ordered=False)\n",
    "    df[\"fabric_type\"] = df[\"fabric_type\"].astype(fabric_type_types)\n",
    "    gender_types = CategoricalDtype(categories=[\"B\", \"G\", \"K\", \"M\", \"U\", \"Y\", \"W\"], ordered=False)\n",
    "    df[\"gender\"] = df[\"gender\"].astype(gender_types)\n",
    "    made_in_types = CategoricalDtype(categories=[\"AU\", \"BD\", \"BE\", \"BG\", \"BR\", \"CN\", \"CO\", \"CY\", \"DE\", \"DK\", \"EG\", \"ES\", \"FI\", \"FR\", \"GB\", \"GE\", \"GR\", \"HK\", \"IE\", \"IN\", \"IT\", \"JP\", \"KR\", \"LT\", \"LV\", \"ML\", \"MX\", \"PK\", \"RO\", \"SE\", \"TH\", \"TR\", \"TW\", \"US\", \"VE\", \"VN\"], ordered=False)\n",
    "    df[\"made_in\"] = df[\"made_in\"].astype(made_in_types)\n",
    "    season_types = CategoricalDtype(categories=[\"AYR\", \"MID\", \"SUM\", \"WIN\"], ordered=False)\n",
    "    df[\"season\"] = df[\"season\"].astype(season_types)\n",
    "    \n",
    "    # Use ordered categories for size\n",
    "    size_type = CategoricalDtype(categories=[\"XS\", \"S\", \"M\", \"L\", \"XL\", \"XXL\"], ordered=True)\n",
    "    df[\"size\"] = df[\"size\"].astype(size_type)\n",
    "           \n",
    "    y = df[\"weight\"]\n",
    "    df = df.drop([\"weight\"], axis=1)\n",
    "    \n",
    "    # Convert the categoricals into a one-hot vector of binary variables\n",
    "    X = pd.get_dummies(df)\n",
    "    \n",
    "    # Fill in 0 for NA in ftp_ columns\n",
    "    X = X.fillna(0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def searchK():    \n",
    "    number_to_try = 12\n",
    "    losses = np.zeros((number_to_try+1), dtype=np.float64)\n",
    "    for n in range(8,number_to_try+1):\n",
    "        knn = neighbors.KNeighborsRegressor(n, algorithm='ball_tree', weights='uniform')\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        # Use simple RMSE\n",
    "        elementwise_loss = np.sqrt(np.square(y_test-y_pred))\n",
    "        losses[n] = np.sum(elementwise_loss)\n",
    "\n",
    "    ax = sns.lineplot(x=range(number_to_try+1), y=losses).set_title(\"KNN, number of neighbors vs loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_weight_predictor(X_train, y_train, n_neighbors=9):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, algorithm='ball_tree', weights='uniform')\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    path = f\"{DATA_PATH}/{filename}\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"Saved model to disk at {path}\")\n",
    "    return\n",
    "\n",
    "def load_model(filename):\n",
    "    path = f\"{DATA_PATH}/{filename}\"\n",
    "    knn = joblib.load(path)\n",
    "    print(f\"Loaded model from disk at {path}\")\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for training weight estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_path, samples_to_use=200000, n_neighbors=9):\n",
    "    df = load_source_data(path=data_path)\n",
    "    if (samples_to_use < df.shape[0]):\n",
    "        print(f\"Using only the first {samples_to_use} samples of {df.shape[0]} available\")\n",
    "        df = df[:samples_to_use]\n",
    "\n",
    "    X, y = preprocess(df)\n",
    "\n",
    "    print(f\"X.shape: {X.shape}\")\n",
    "    # Train-test-split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    knn = train_weight_predictor(X_train, y_train, n_neighbors=n_neighbors)\n",
    "    rmse, r2 = evaluate(knn, X_test, y_test)\n",
    "    print(f\"Trained K-nearest neighbor regressor K={n_neighbors}, training samples={len(y_train)} for estimating weight.\")\n",
    "    print(f\"RSME={rmse}, R2={r2}\")\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save a weight estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only the first 100000 samples of 15000000 available\n",
      "X.shape: (40163, 333)\n",
      "Trained K-nearest neighbor regressor K=9, training samples=32130 for estimating weight.\n",
      "RSME=0.7147649993971269, R2=-0.027976713602003045\n",
      "Saved model to disk at ../data/nearestneighbor_weight_regression_9.sav\n"
     ]
    }
   ],
   "source": [
    "n_neighbors=9\n",
    "filename = f\"nearestneighbor_weight_regression_{n_neighbors}.sav\"\n",
    "\n",
    "model = train_model(data_path=DATA_PATH, samples_to_use=100000, n_neighbors=9)\n",
    "save_model(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict weight values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weight (model_filename=filename, test_file=TEST_FILE):\n",
    "    model = load_model(model_filename)\n",
    "    req_df = pd.read_csv(test_file)\n",
    "    X_req, weight_req_true = preprocess(req_df, drop_weight_na=False)\n",
    "    print(f\"X_req.shape: {X_req.shape}\") \n",
    "    weight_req_pred = model.predict(X_req)\n",
    "    \n",
    "    print(\"True weights: \\n\", weight_req_true)\n",
    "    print(\"Predicted weights: \", weight_req_pred)\n",
    "    return weight_req_pred              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk at ../data/nearestneighbor_weight_regression_9.sav\n",
      "X_req.shape: (10, 333)\n",
      "True weights: \n",
      " 0      NaN\n",
      "1    0.093\n",
      "2    0.182\n",
      "3      NaN\n",
      "4      NaN\n",
      "5      NaN\n",
      "6      NaN\n",
      "7    0.140\n",
      "8    0.017\n",
      "9      NaN\n",
      "Name: weight, dtype: float64\n",
      "Predicted weights:  [0.54033333 1.058      0.74744444 0.66722222 0.46711111 0.36311111\n",
      " 0.51733333 0.44377778 0.02166667 0.86422222]\n"
     ]
    }
   ],
   "source": [
    "weight_req_pred = predict_weight(model_filename=filename, test_file=TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54033333, 1.058     , 0.74744444, 0.66722222, 0.46711111,\n",
       "       0.36311111, 0.51733333, 0.44377778, 0.02166667, 0.86422222])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_req_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Compensate EDA Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
