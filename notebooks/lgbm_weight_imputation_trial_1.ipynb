{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Carbon Gradient Boosting Model",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFaO6B23M6wUzWTW5twWqf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carbonpredict/carbonpredict/blob/master/notebooks/lgbm_weight_imputation_trial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqgEZ11ftuKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1cb4f4e7-bef5-43ba-e895-e8f3eb3d79da"
      },
      "source": [
        "!git clone https://github.com/Compensate-Operations/emission-sample-data.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'emission-sample-data'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 33 (delta 8), reused 18 (delta 8), pack-reused 13\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzsSK4OiMGtK",
        "colab_type": "text"
      },
      "source": [
        "# Install required packages\n",
        "\n",
        "LightGBM will be updated to GPU version. It is about 1.5x faster in Colab, but with decent CPU the training will be fast enough anyway so GPU might not be needed. Simply uncomment the lightgbm package and remove device='gpu' parameter from the model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ84jPY36f-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install lightgbm --upgrade --install-option=--gpu\n",
        "!pip3 install bayesian-optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzMMbyvBuAoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!for i in /content/emission-sample-data/datasets/textile-v1.0.0/*.tgz; do tar -zxvf \"$i\" ;done\n",
        "\n",
        "!ls -lah\n",
        "!rm ._textile-v1.0.0-5.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ozr6nXUvSZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "6b0143b5-fc3c-48ca-9581-e3092aa87738"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "content = sorted(filter(lambda x: x.endswith(\".csv\"), os.listdir(\"/content/\")))\n",
        "\n",
        "df = pd.concat((pd.read_csv(f) for f in content))\n",
        "df"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>category-1</th>\n",
              "      <th>category-2</th>\n",
              "      <th>category-3</th>\n",
              "      <th>co2_total</th>\n",
              "      <th>colour</th>\n",
              "      <th>fabric_type</th>\n",
              "      <th>ftp_acrylic</th>\n",
              "      <th>ftp_cotton</th>\n",
              "      <th>ftp_elastane</th>\n",
              "      <th>ftp_linen</th>\n",
              "      <th>ftp_other</th>\n",
              "      <th>ftp_polyamide</th>\n",
              "      <th>ftp_polyester</th>\n",
              "      <th>ftp_polypropylene</th>\n",
              "      <th>ftp_silk</th>\n",
              "      <th>ftp_viscose</th>\n",
              "      <th>ftp_wool</th>\n",
              "      <th>gender</th>\n",
              "      <th>label</th>\n",
              "      <th>made_in</th>\n",
              "      <th>season</th>\n",
              "      <th>size</th>\n",
              "      <th>unspsc_code</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b111</td>\n",
              "      <td>womenswear</td>\n",
              "      <td>uniform</td>\n",
              "      <td>jacket</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blue gray</td>\n",
              "      <td>K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>XS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b82</td>\n",
              "      <td>home</td>\n",
              "      <td>home</td>\n",
              "      <td>curtain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>teal</td>\n",
              "      <td>W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>XXL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b107</td>\n",
              "      <td>menswear</td>\n",
              "      <td>headgear</td>\n",
              "      <td>knit-cap</td>\n",
              "      <td>NaN</td>\n",
              "      <td>metal</td>\n",
              "      <td>K</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>XL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b111</td>\n",
              "      <td>home</td>\n",
              "      <td>home</td>\n",
              "      <td>curtain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>light grey</td>\n",
              "      <td>K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b83</td>\n",
              "      <td>womenswear</td>\n",
              "      <td>footwear</td>\n",
              "      <td>socks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bondi blue</td>\n",
              "      <td>K</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>43.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>VN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999995</th>\n",
              "      <td>b90</td>\n",
              "      <td>womenswear</td>\n",
              "      <td>nightwear</td>\n",
              "      <td>pyjama</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pink</td>\n",
              "      <td>K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>46.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999996</th>\n",
              "      <td>b133</td>\n",
              "      <td>baby</td>\n",
              "      <td>footwear</td>\n",
              "      <td>socks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wheat</td>\n",
              "      <td>K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>XL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999997</th>\n",
              "      <td>b1</td>\n",
              "      <td>menswear</td>\n",
              "      <td>outerwear</td>\n",
              "      <td>pants</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gold</td>\n",
              "      <td>W</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999998</th>\n",
              "      <td>b73</td>\n",
              "      <td>menswear</td>\n",
              "      <td>accessory</td>\n",
              "      <td>backpack</td>\n",
              "      <td>NaN</td>\n",
              "      <td>amber</td>\n",
              "      <td>K</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>XL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999999</th>\n",
              "      <td>b122</td>\n",
              "      <td>menswear</td>\n",
              "      <td>men-undergarments</td>\n",
              "      <td>boxer-brief</td>\n",
              "      <td>NaN</td>\n",
              "      <td>lime</td>\n",
              "      <td>K</td>\n",
              "      <td>6.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000000 rows Ã— 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        brand  category-1         category-2  ... size  unspsc_code weight\n",
              "0        b111  womenswear            uniform  ...   XS          NaN  1.062\n",
              "1         b82        home               home  ...  XXL          NaN    NaN\n",
              "2        b107    menswear           headgear  ...   XL          NaN  0.160\n",
              "3        b111        home               home  ...    M          NaN    NaN\n",
              "4         b83  womenswear           footwear  ...    M          NaN  0.029\n",
              "...       ...         ...                ...  ...  ...          ...    ...\n",
              "2999995   b90  womenswear          nightwear  ...    L          NaN    NaN\n",
              "2999996  b133        baby           footwear  ...   XL          NaN    NaN\n",
              "2999997    b1    menswear          outerwear  ...    S          NaN    NaN\n",
              "2999998   b73    menswear          accessory  ...   XL          NaN    NaN\n",
              "2999999  b122    menswear  men-undergarments  ...    S          NaN    NaN\n",
              "\n",
              "[15000000 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_LZo6TxzWTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cat_cols = [\"category-1\", \"category-2\", \"category-3\", \n",
        "            \"size\", \"made_in\", \"gender\", \"colour\", \n",
        "            \"brand\", \"fabric_type\", \"season\"]\n",
        "\n",
        "#df[\"season\"].fillna(\"no_season\", inplace=True)\n",
        "\n",
        "df[cat_cols] = df[cat_cols].astype(\"category\")\n",
        "\n",
        "X = df[~df[\"co2_total\"].isna()]\n",
        "y = X[\"co2_total\"].copy()\n",
        "X = X.drop(\"co2_total\", axis=1)\n",
        "#X = X.drop(\"weight\", axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1GKIooQMEis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "c34b4f74-7c06-47c1-8f89-8a1d1fb7ef51"
      },
      "source": [
        "\n",
        "X['weight'] = X.groupby(['category-1', 'category-2', 'category-3'])['weight'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "X[X['weight'].isna()]\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>brand</th>\n",
              "      <th>category-1</th>\n",
              "      <th>category-2</th>\n",
              "      <th>category-3</th>\n",
              "      <th>colour</th>\n",
              "      <th>fabric_type</th>\n",
              "      <th>ftp_acrylic</th>\n",
              "      <th>ftp_cotton</th>\n",
              "      <th>ftp_elastane</th>\n",
              "      <th>ftp_linen</th>\n",
              "      <th>ftp_other</th>\n",
              "      <th>ftp_polyamide</th>\n",
              "      <th>ftp_polyester</th>\n",
              "      <th>ftp_polypropylene</th>\n",
              "      <th>ftp_silk</th>\n",
              "      <th>ftp_viscose</th>\n",
              "      <th>ftp_wool</th>\n",
              "      <th>gender</th>\n",
              "      <th>label</th>\n",
              "      <th>made_in</th>\n",
              "      <th>season</th>\n",
              "      <th>size</th>\n",
              "      <th>unspsc_code</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [brand, category-1, category-2, category-3, colour, fabric_type, ftp_acrylic, ftp_cotton, ftp_elastane, ftp_linen, ftp_other, ftp_polyamide, ftp_polyester, ftp_polypropylene, ftp_silk, ftp_viscose, ftp_wool, gender, label, made_in, season, size, unspsc_code, weight]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Jx53xbTM7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "cdcfd404-fca8-44c5-d04c-fdd3a5c28a01"
      },
      "source": [
        "X_imp"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23         0.122000\n",
              "34         0.937707\n",
              "51         0.876408\n",
              "56         0.115386\n",
              "74         0.876408\n",
              "             ...   \n",
              "2999961    0.864440\n",
              "2999970    0.355742\n",
              "2999980    0.024577\n",
              "2999981    0.024577\n",
              "2999984    0.591435\n",
              "Name: weight, Length: 1699515, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmOhz0jFxFnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9cfbe74c-cc14-48d4-ec3d-b48547e36287"
      },
      "source": [
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "lgb_clf = None\n",
        "\n",
        "def run_lgb(X, y, params):\n",
        "    kf = KFold(n_splits=5, shuffle=True)\n",
        "    preds = np.zeros(len(X))\n",
        "    nrounds = 5000\n",
        "    early_stopping_rounds = 200\n",
        "\n",
        "    models = []\n",
        "\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
        "        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
        "\n",
        "        trn_data = lgb.Dataset(X_train, label=y_train)\n",
        "        val_data = lgb.Dataset(X_valid, label=y_valid)\n",
        "\n",
        "        lgb_clf = lgb.train(params,\n",
        "                        trn_data,\n",
        "                        nrounds,\n",
        "                        valid_sets = [trn_data, val_data],\n",
        "                        early_stopping_rounds = early_stopping_rounds,\n",
        "                        verbose_eval = 100)\n",
        "\n",
        "        preds[val_idx] = lgb_clf.predict(X_valid)\n",
        "\n",
        "        models.append(lgb_clf)\n",
        "\n",
        "    s_rmse = np.sqrt(mean_squared_error(y, preds))\n",
        "    s_r2 = r2_score(y, preds)\n",
        "    \n",
        "    print(\"RMSE Score:\", s_rmse)\n",
        "    print(\"R^2 Score:\", s_r2)\n",
        "\n",
        "    return models, s_rmse\n",
        "\n",
        "\n",
        "# 0.7981221901359424\n",
        "\n",
        "params = {'bagging_fraction': 1.0,\n",
        " 'bagging_freq': 1,\n",
        " 'boosting_type': 'gbdt',\n",
        " 'colsample_bytree': 0.4,\n",
        " 'lambda_l1': 0.0,\n",
        " 'lambda_l2': 0.0,\n",
        " 'learning_rate': 0.1,\n",
        " 'max_depth': 12,\n",
        " 'metric': 'rmse',\n",
        " 'n_jobs': -1,\n",
        " 'num_leavs': 300.0,\n",
        " 'objective': 'regression',\n",
        " 'device': 'gpu',\n",
        " 'seed': 42}\n",
        "\n",
        "models, _ = run_lgb(X, y, params)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\ttraining's rmse: 10.1276\tvalid_1's rmse: 10.2321\n",
            "[200]\ttraining's rmse: 9.76296\tvalid_1's rmse: 10.0189\n",
            "[300]\ttraining's rmse: 9.59233\tvalid_1's rmse: 9.96708\n",
            "[400]\ttraining's rmse: 9.46855\tvalid_1's rmse: 9.94213\n",
            "[500]\ttraining's rmse: 9.36225\tvalid_1's rmse: 9.92739\n",
            "[600]\ttraining's rmse: 9.26454\tvalid_1's rmse: 9.91256\n",
            "[700]\ttraining's rmse: 9.17887\tvalid_1's rmse: 9.91107\n",
            "[800]\ttraining's rmse: 9.08791\tvalid_1's rmse: 9.90815\n",
            "[900]\ttraining's rmse: 9.01022\tvalid_1's rmse: 9.90739\n",
            "[1000]\ttraining's rmse: 8.95247\tvalid_1's rmse: 9.90896\n",
            "Early stopping, best iteration is:\n",
            "[832]\ttraining's rmse: 9.06729\tvalid_1's rmse: 9.90384\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\ttraining's rmse: 10.0806\tvalid_1's rmse: 10.2572\n",
            "[200]\ttraining's rmse: 9.73374\tvalid_1's rmse: 10.0464\n",
            "[300]\ttraining's rmse: 9.55194\tvalid_1's rmse: 9.9904\n",
            "[400]\ttraining's rmse: 9.41887\tvalid_1's rmse: 9.95713\n",
            "[500]\ttraining's rmse: 9.31823\tvalid_1's rmse: 9.93956\n",
            "[600]\ttraining's rmse: 9.23751\tvalid_1's rmse: 9.92868\n",
            "[700]\ttraining's rmse: 9.15882\tvalid_1's rmse: 9.92064\n",
            "[800]\ttraining's rmse: 9.0806\tvalid_1's rmse: 9.91394\n",
            "[900]\ttraining's rmse: 9.01368\tvalid_1's rmse: 9.91597\n",
            "Early stopping, best iteration is:\n",
            "[785]\ttraining's rmse: 9.08811\tvalid_1's rmse: 9.91304\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\ttraining's rmse: 10.1134\tvalid_1's rmse: 10.1288\n",
            "[200]\ttraining's rmse: 9.75956\tvalid_1's rmse: 9.94392\n",
            "[300]\ttraining's rmse: 9.57956\tvalid_1's rmse: 9.88743\n",
            "[400]\ttraining's rmse: 9.45097\tvalid_1's rmse: 9.85727\n",
            "[500]\ttraining's rmse: 9.33592\tvalid_1's rmse: 9.83679\n",
            "[600]\ttraining's rmse: 9.23639\tvalid_1's rmse: 9.82002\n",
            "[700]\ttraining's rmse: 9.14596\tvalid_1's rmse: 9.81724\n",
            "[800]\ttraining's rmse: 9.06843\tvalid_1's rmse: 9.81478\n",
            "[900]\ttraining's rmse: 8.99818\tvalid_1's rmse: 9.81538\n",
            "[1000]\ttraining's rmse: 8.9328\tvalid_1's rmse: 9.81318\n",
            "[1100]\ttraining's rmse: 8.86772\tvalid_1's rmse: 9.81436\n",
            "Early stopping, best iteration is:\n",
            "[971]\ttraining's rmse: 8.95344\tvalid_1's rmse: 9.81209\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\ttraining's rmse: 10.1127\tvalid_1's rmse: 10.2453\n",
            "[200]\ttraining's rmse: 9.76355\tvalid_1's rmse: 10.048\n",
            "[300]\ttraining's rmse: 9.58393\tvalid_1's rmse: 9.99095\n",
            "[400]\ttraining's rmse: 9.44224\tvalid_1's rmse: 9.95433\n",
            "[500]\ttraining's rmse: 9.31952\tvalid_1's rmse: 9.93998\n",
            "[600]\ttraining's rmse: 9.22282\tvalid_1's rmse: 9.92903\n",
            "[700]\ttraining's rmse: 9.13988\tvalid_1's rmse: 9.92492\n",
            "[800]\ttraining's rmse: 9.0624\tvalid_1's rmse: 9.91678\n",
            "[900]\ttraining's rmse: 8.99083\tvalid_1's rmse: 9.90921\n",
            "[1000]\ttraining's rmse: 8.92549\tvalid_1's rmse: 9.9102\n",
            "[1100]\ttraining's rmse: 8.86517\tvalid_1's rmse: 9.90993\n",
            "[1200]\ttraining's rmse: 8.80733\tvalid_1's rmse: 9.90798\n",
            "[1300]\ttraining's rmse: 8.7453\tvalid_1's rmse: 9.90673\n",
            "[1400]\ttraining's rmse: 8.68807\tvalid_1's rmse: 9.90844\n",
            "Early stopping, best iteration is:\n",
            "[1261]\ttraining's rmse: 8.77134\tvalid_1's rmse: 9.90523\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\ttraining's rmse: 10.0845\tvalid_1's rmse: 10.2616\n",
            "[200]\ttraining's rmse: 9.75104\tvalid_1's rmse: 10.0793\n",
            "[300]\ttraining's rmse: 9.55779\tvalid_1's rmse: 10.0046\n",
            "[400]\ttraining's rmse: 9.42938\tvalid_1's rmse: 9.97372\n",
            "[500]\ttraining's rmse: 9.31306\tvalid_1's rmse: 9.95531\n",
            "[600]\ttraining's rmse: 9.22305\tvalid_1's rmse: 9.94619\n",
            "[700]\ttraining's rmse: 9.13488\tvalid_1's rmse: 9.93985\n",
            "[800]\ttraining's rmse: 9.05224\tvalid_1's rmse: 9.93709\n",
            "[900]\ttraining's rmse: 8.9834\tvalid_1's rmse: 9.93537\n",
            "[1000]\ttraining's rmse: 8.92156\tvalid_1's rmse: 9.93469\n",
            "Early stopping, best iteration is:\n",
            "[847]\ttraining's rmse: 9.02317\tvalid_1's rmse: 9.93372\n",
            "RMSE Score: 9.893673539775255\n",
            "R^2 Score: 0.8711712034149216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG1klSVfWn0N",
        "colab_type": "text"
      },
      "source": [
        "# Weight Imputation For Training\n",
        "\n",
        "## No imputation\n",
        "\n",
        "RMSE Score: 9.699965230008726\n",
        "R^2 Score: 0.8761664984846785\n",
        "\n",
        "## Imputing with category-3\n",
        "\n",
        "Category-3 should take us to correct direction, as usually t-shirt weights more than socks.\n",
        "\n",
        "RMSE Score: 9.736979657961824\n",
        "R^2 Score: 0.8752196143425424\n",
        "\n",
        "It seems that the result is not much better, but it's not much worse either so let's continue. \n",
        "\n",
        "## Imputing with category-3, season\n",
        "\n",
        "I added season as it is important variable for weight, e.g. winter clothing typically weights more than summer clothing.\n",
        "\n",
        "RMSE Score: 9.743931763166684\n",
        "R^2 Score: 0.8750413668597842\n",
        "\n",
        "Could be a bug in implementation how season missing values are handles. Needs more tuning.\n",
        "\n",
        "## Imputing with category-1, category-2, category-3\n",
        "\n",
        "RMSE Score: 9.893673539775255\n",
        "R^2 Score: 0.8711712034149216\n",
        "\n",
        "## Summary\n",
        "\n",
        "It is possible that imputing the multiple columns might not work as I expect. I'll come back to this. However, with single column category-1 our model doesn't get much worse, so it means that we could keep the 0.87 level simply with imputing with category-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U6qTWtb92QH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "bac9b982-63c0-4429-d27d-91b198a0ac38"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cols = X.columns.tolist()\n",
        "\n",
        "feature_imp = pd.DataFrame(\n",
        "    sorted(zip(models[0].feature_importance(importance_type=\"gain\"), cols)),\n",
        "    columns=[\"value\", \"feature\"])\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.barplot(\n",
        "    x=\"value\",\n",
        "    y=\"feature\",\n",
        "    data=feature_imp.sort_values(by=\"value\", ascending=False).head(50))\n",
        "\n",
        "plt.savefig(\"features.png\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4c48a14c7ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m feature_imp = pd.DataFrame(\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     columns=[\"value\", \"feature\"])\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lgb_clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk9WPZ7zKg3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_lgb_bayesian(num_leaves, max_depth, lambda_l1, lambda_l2, bagging_fraction, bagging_freq, colsample_bytree, learning_rate):\n",
        "    params = {\n",
        "        'boosting_type': 'gbdt',\n",
        "        'metric': 'rmse',\n",
        "        'objective': 'regression',\n",
        "        'n_jobs': -1,\n",
        "        'seed': 42,\n",
        "        'num_leaves': int(num_leaves),\n",
        "        'learning_rate': learning_rate,\n",
        "        'max_depth': int(max_depth),\n",
        "        'lambda_l1': lambda_l1,\n",
        "        'lambda_l2': lambda_l2,\n",
        "        'bagging_fraction': bagging_fraction,\n",
        "        'bagging_freq': int(bagging_freq),\n",
        "        'colsample_bytree': colsample_bytree,\n",
        "        'verbose': 0,\n",
        "        'device':'gpu' \n",
        "    }\n",
        "    print(\"Trying params\", params)\n",
        "\n",
        "    _, score = run_lgb(X, y, params)\n",
        "    \n",
        "    return score\n",
        "\n",
        "if False:\n",
        "    from bayes_opt import BayesianOptimization\n",
        "\n",
        "    bounds_lgb = {\n",
        "        'num_leaves': (20, 300),\n",
        "        'max_depth': (8, 12),\n",
        "        'lambda_l1': (0, 5),\n",
        "        'lambda_l2': (0, 5),\n",
        "        'bagging_fraction': (0.4, 1),\n",
        "        'bagging_freq': (1, 10),\n",
        "        'colsample_bytree': (0.4, 1),\n",
        "        'learning_rate': (0.025, 0.1),\n",
        "    }\n",
        "\n",
        "    lgb_bo = BayesianOptimization(run_lgb_bayesian, bounds_lgb, random_state = 42)\n",
        "    lgb_bo.maximize(init_points = 20, n_iter = 5, acq = 'ucb', xi = 0.0, alpha = 1e-6)\n",
        "\n",
        "    params = {\n",
        "        'boosting_type': 'gbdt',\n",
        "        'metric': 'rmse',\n",
        "        'objective': 'regression',\n",
        "        'n_jobs': -1,\n",
        "        'seed': 42,\n",
        "        'num_leaves': lgb_bo.max['params']['num_leaves'],\n",
        "        'learning_rate': lgb_bo.max['params']['learning_rate'],\n",
        "        'max_depth': int(lgb_bo.max['params']['max_depth']),\n",
        "        'lambda_l1': lgb_bo.max['params']['lambda_l1'],\n",
        "        'lambda_l2': lgb_bo.max['params']['lambda_l2'],\n",
        "        'bagging_fraction': lgb_bo.max['params']['bagging_fraction'],\n",
        "        'bagging_freq': int(lgb_bo.max['params']['bagging_freq']),\n",
        "        'colsample_bytree': lgb_bo.max['params']['colsample_bytree']\n",
        "    }\n",
        "\n",
        "    print(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7ohs9_SI2TH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "efcb012d-5c02-47b3-d202-e179f87e5323"
      },
      "source": [
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.4,\n",
              " 'bagging_freq': 10,\n",
              " 'boosting_type': 'gbdt',\n",
              " 'colsample_bytree': 0.4,\n",
              " 'lambda_l1': 0.0,\n",
              " 'lambda_l2': 0.0,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_depth': 12,\n",
              " 'metric': 'rmse',\n",
              " 'n_jobs': -1,\n",
              " 'num_leaves': 300.0,\n",
              " 'objective': 'regression',\n",
              " 'seed': 42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwPn--jLQZn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = df[df[\"co2_total\"].isna()]\n",
        "\n",
        "t.sample(100).to_csv(\"test.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}