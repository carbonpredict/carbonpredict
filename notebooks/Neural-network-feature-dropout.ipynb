{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../mnt_emission_data' # Need to have the data as CSV files in this path\n",
    "#base_dir = '../data' # Need to have the data as CSV files in this path\n",
    "#base_dir = '../data/mini' # Need to have the data as CSV files in this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_data(path):\n",
    "    content = sorted(filter(lambda x: x.endswith(\".csv\"), os.listdir(path)))\n",
    "    X = pd.concat((pd.read_csv(f'{path}/{f}') for f in content))\n",
    "    X = X[~X['co2_total'].isna()]\n",
    "\n",
    "    # Use only 100000 samples to test\n",
    "    #X = X[:100000]\n",
    "    \n",
    "    y = X['co2_total'].copy()\n",
    "    X = X.drop('co2_total', axis=1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneLayerModelRobust(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden1, n_output, bs, p):\n",
    "        super().__init__()\n",
    "        self.bs = bs\n",
    "        self.drop_layer = nn.Dropout(p=p)\n",
    "        self.input_layer = nn.Linear(n_input, n_hidden1)\n",
    "        self.hidden1 = nn.Linear(n_hidden1, n_output)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.drop_layer(x)\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerModel(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden1, n_hidden2, n_output, bs):\n",
    "        super().__init__()\n",
    "        self.bs = bs\n",
    "        self.input_layer = nn.Linear(n_input, n_hidden1)\n",
    "        self.hidden1 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.hidden2 = nn.Linear(n_hidden2, n_output)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkOneLayerFFRobust:\n",
    "    \"\"\"\n",
    "    A feedforward neural network model with one hidden layer that uses feature dropout during training. \n",
    "    The number of neurons in the hidden layer can be given as a parameter to the constructor (default 1024).\n",
    "    The model will train until 5 epochs have passed without the test RMSE improving. \n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_neurons=1024, droprate=0.2):\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.droprate = droprate\n",
    "        self.__set_filename()\n",
    "        self.model = None\n",
    "    \n",
    "    def __set_filename(self):\n",
    "        self.filename = f\"neural_onelayer_robust-hidden_{self.hidden_neurons}.model\"\n",
    "\n",
    "    #def preprocess(self, X):\n",
    "    def __preprocess(self, X):\n",
    "        # Drop empty features (dataset v. 1.0.0): unspsc_code, label \n",
    "        X = X.drop([\"label\", \"unspsc_code\"], axis=1)\n",
    "\n",
    "        # Use unordered caterogies for several columns. List category values to support use cases when some\n",
    "        # values are absent from a batch of source data.\n",
    "        brand_types = CategoricalDtype(categories=[\"b0\", \"b1\", \"b10\", \"b100\", \"b101\", \"b102\", \"b103\", \"b104\", \"b105\", \"b106\", \"b107\", \"b108\", \"b109\", \"b11\", \"b110\", \"b111\", \"b112\", \"b113\", \"b114\", \"b115\", \"b116\", \"b117\", \"b118\", \"b119\", \"b12\", \"b120\", \"b121\", \"b122\", \"b123\", \"b124\", \"b125\", \"b126\", \"b127\", \"b128\", \"b129\", \"b13\", \"b130\", \"b131\", \"b132\", \"b133\", \"b134\", \"b135\", \"b136\", \"b137\", \"b138\", \"b139\", \"b14\", \"b140\", \"b141\", \"b142\", \"b143\", \"b144\", \"b145\", \"b146\", \"b147\", \"b148\", \"b149\", \"b15\", \"b16\", \"b17\", \"b18\", \"b19\", \"b2\", \"b20\", \"b21\", \"b22\", \"b23\", \"b24\", \"b25\", \"b26\", \"b27\", \"b28\", \"b29\", \"b3\", \"b30\", \"b31\", \"b32\", \"b33\", \"b34\", \"b35\", \"b36\", \"b37\", \"b38\", \"b39\", \"b4\", \"b40\", \"b41\", \"b42\", \"b43\", \"b44\", \"b45\", \"b46\", \"b47\", \"b48\", \"b49\", \"b5\", \"b50\", \"b51\", \"b52\", \"b53\", \"b54\", \"b55\", \"b56\", \"b57\", \"b58\", \"b59\", \"b6\", \"b60\", \"b61\", \"b62\", \"b63\", \"b64\", \"b65\", \"b66\", \"b67\", \"b68\", \"b69\", \"b7\", \"b70\", \"b71\", \"b72\", \"b73\", \"b74\", \"b75\", \"b76\", \"b77\", \"b78\", \"b79\", \"b8\", \"b80\", \"b81\", \"b82\", \"b83\", \"b84\", \"b85\", \"b86\", \"b87\", \"b88\", \"b89\", \"b9\", \"b90\", \"b91\", \"b92\", \"b93\", \"b94\", \"b95\", \"b96\", \"b97\", \"b98\", \"b99\"], ordered=False)\n",
    "        X[\"brand\"] = X[\"brand\"].astype(brand_types)\n",
    "        cat1_types =  CategoricalDtype(categories=[\"baby\", \"clothing\", \"home\", \"kidswear\", \"menswear\", \"womenswear\"], ordered=False)\n",
    "        X[\"category-1\"] = X[\"category-1\"].astype(cat1_types)\n",
    "        cat2_types = CategoricalDtype(categories=[\"home\", \"footwear\", \"nightwear\", \"thermals\", \"outerwear\", \"accessory\", \"uniform\", \"suit\", \"swimwear\", \"headgear\", \"sportswear\", \"costume\", \"clothing\", \"undergarments\", \"baby\", \"dress\", \"beachwear\", \"men-undergarments\", \"hosiery\", \"women-beachwear\", \"women-undergarments\", \"women-sportswear\"], ordered=False)\n",
    "        X[\"category-2\"] = X[\"category-2\"].astype(cat2_types)\n",
    "        cat3_types = CategoricalDtype(categories=[\"backpack\", \"bikin\", \"body\", \"boxer-brief\", \"bra\", \"brief\", \"briefs\", \"cap\", \"coats\", \"costume\", \"curtain\", \"dress\", \"evening-dress\", \"fancy-dress\", \"flat-cap\", \"gloves\", \"hat\", \"hoodie\", \"jacket\", \"jean-shorts\", \"jeans\", \"jersey\", \"knit-cap\", \"knitwear\", \"long-sleeved-top\", \"mat\", \"overalls\", \"panties\", \"pants\", \"pillow\", \"pyjama\", \"scarf\", \"sheets\", \"shorts\", \"skirts\", \"snow-suit\", \"socks\", \"sport-bra\", \"stockings\", \"swimsuit\", \"T-shirt\", \"tie\", \"tights\", \"top\", \"towel\", \"trousers\", \"underpants\", \"wedding-dress\"], ordered=False)\n",
    "        X[\"category-3\"] = X[\"category-3\"].astype(cat3_types)\n",
    "        colour_types = CategoricalDtype(categories=[\"Ivory\", \"amber\", \"aquamarine\", \"black\", \"blue\", \"blue gray\", \"bondi blue\", \"brown\", \"colourful\", \"dark green\", \"dark grey\", \"gold\", \"golden\", \"gray\", \"green\", \"grey\", \"indigo\", \"light brown\", \"light grey\", \"lime\", \"maroon\", \"metal\", \"mosaic\", \"mustard\", \"natural\", \"navy\", \"neon\", \"orange\", \"peach\", \"pink\", \"purple\", \"red\", \"silver\", \"teal\", \"turquoise\", \"unbleached\", \"unknown\", \"violet\", \"wheat\", \"white\", \"yellow\"], ordered=False)\n",
    "        X[\"colour\"] = X[\"colour\"].astype(colour_types)\n",
    "        fabric_type_types = CategoricalDtype(categories=[\"K\", \"W\"], ordered=False)\n",
    "        X[\"fabric_type\"] = X[\"fabric_type\"].astype(fabric_type_types)\n",
    "        gender_types = CategoricalDtype(categories=[\"B\", \"G\", \"K\", \"M\", \"U\", \"Y\", \"W\"], ordered=False)\n",
    "        X[\"gender\"] = X[\"gender\"].astype(gender_types)\n",
    "        made_in_types = CategoricalDtype(categories=[\"AU\", \"BD\", \"BE\", \"BG\", \"BR\", \"CN\", \"CO\", \"CY\", \"DE\", \"DK\", \"EG\", \"ES\", \"FI\", \"FR\", \"GB\", \"GE\", \"GR\", \"HK\", \"IE\", \"IN\", \"IT\", \"JP\", \"KR\", \"LT\", \"LV\", \"ML\", \"MX\", \"PK\", \"RO\", \"SE\", \"TH\", \"TR\", \"TW\", \"US\", \"VE\", \"VN\"], ordered=False)\n",
    "        X[\"made_in\"] = X[\"made_in\"].astype(made_in_types)\n",
    "        season_types = CategoricalDtype(categories=[\"AYR\", \"MID\", \"SUM\", \"WIN\"], ordered=False)\n",
    "        X[\"season\"] = X[\"season\"].astype(season_types)\n",
    "\n",
    "        # Use ordered categories for size\n",
    "        size_type = CategoricalDtype(categories=[\"XS\", \"S\", \"M\", \"L\", \"XL\", \"XXL\"], ordered=True)\n",
    "        X[\"size\"] = X[\"size\"].astype(size_type)\n",
    "\n",
    "        # Convert the categoricals into a one-hot vector of binary variables\n",
    "        X = pd.get_dummies(X)\n",
    "        #print(X)\n",
    "\n",
    "        # Fill in 0 for NA in ftp_ columns\n",
    "        X = X.fillna(0)\n",
    "        #print(X)\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "        #print(X_scaled)\n",
    "\n",
    "        return X_scaled\n",
    "\n",
    "    def __save_model(self, base_dir):\n",
    "        print(f\"Saving neural network one hidden layer model to disk at {base_dir}/{self.filename}\")\n",
    "        torch.save(self.model, f\"{base_dir}/{self.filename}\")\n",
    "\n",
    "    def __get_dataloader(self, X, y, bs=1000, test_size=0.2):\n",
    "        X = self.__preprocess(X)\n",
    "        X = X.to_numpy(dtype='float32')\n",
    "        y = y.to_numpy(dtype='float32')\n",
    "        \n",
    "        y = y.reshape((-1,1))\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        train_dataloader = DataLoader(TensorDataset(\n",
    "            torch.tensor(X_train, dtype=torch.float),\n",
    "            torch.tensor(y_train, dtype=torch.float)),\n",
    "            shuffle=True,\n",
    "            batch_size=bs)\n",
    "\n",
    "        test_dataloader = DataLoader(TensorDataset(\n",
    "            torch.tensor(X_test, dtype=torch.float),\n",
    "            torch.tensor(y_test, dtype=torch.float)),\n",
    "            shuffle=True,\n",
    "            batch_size=bs)      \n",
    "\n",
    "        return train_dataloader, test_dataloader\n",
    "    \n",
    "    def __evaluate(self, dataloader, model, criterion, device):\n",
    "        model.eval()\n",
    "\n",
    "        rmse_scores = []\n",
    "        r2_scores = []\n",
    "        losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                X, y = batch\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = model(X)\n",
    "\n",
    "                loss = criterion(y_pred, y)\n",
    "                losses.append(loss)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y_pred = y_pred.cpu()\n",
    "                    y = y.cpu()\n",
    "                    s_rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "                    s_r2 = r2_score(y, y_pred)\n",
    "\n",
    "                    rmse_scores.append(s_rmse)\n",
    "                    r2_scores.append(s_r2)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        return torch.mean(torch.tensor(losses)), torch.mean(torch.tensor(rmse_scores)), torch.mean(torch.tensor(r2_scores))\n",
    "\n",
    "    def __train(self, train_dataloader, test_dataloader, model, optimizer, criterion, device):\n",
    "        model.train()\n",
    "\n",
    "        best_model = None\n",
    "        best_test_rmse_score = None\n",
    "        best_test_r2_score = None\n",
    "                \n",
    "        fmt = '{:<5} {:12} {:12} {:<9} {:<9} {:<9} {:<9}'\n",
    "        print(fmt.format('Epoch', 'Train loss', 'Valid loss', 'Train RMSE', 'Train R2', 'Test RMSE', 'Test R2'))\n",
    "\n",
    "        epoch = 0\n",
    "        best_score_epoch = 0\n",
    "        while (epoch - best_score_epoch < 4):\n",
    "            epoch = epoch + 1\n",
    "        \n",
    "            for i, batch in enumerate(train_dataloader):\n",
    "                X, y = batch\n",
    "\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(X)\n",
    "                loss = criterion(y_pred, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            \n",
    "            train_loss, train_rmse_score, train_r2_score = self.__evaluate(train_dataloader, model, criterion, device)\n",
    "            test_loss, test_rmse_score, test_r2_score = self.__evaluate(test_dataloader, model, criterion, device)\n",
    "\n",
    "            fmt = '{:<5} {:03.2f} {:03.2f} {:02.2f} {:02.2f} {:02.2f} {:02.2f}'\n",
    "            print(fmt.format(epoch, train_loss, test_loss, train_rmse_score, train_r2_score, test_rmse_score, test_r2_score))\n",
    "        \n",
    "            if ((best_test_rmse_score == None) or (test_rmse_score < best_test_rmse_score)):\n",
    "                best_test_rmse_score = test_rmse_score\n",
    "                best_test_r2_score = test_r2_score\n",
    "                best_score_epoch = epoch\n",
    "                best_model = copy.deepcopy(model)\n",
    "            \n",
    "        print(f\"Neural network one hidden layer robust model trained in {best_score_epoch} epochs with stats RMSE = {best_test_rmse_score}, R2 = {best_test_r2_score}\")\n",
    "\n",
    "        best_model.eval()\n",
    "        return best_model, best_test_r2_score\n",
    "    \n",
    "    def __select_device(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "            print(\"Using GPU!\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print(\"GPU not available, using CPU.\")\n",
    "        return device\n",
    "    \n",
    "    def load(self, base_dir):\n",
    "        print(f\"Loading neural network one hidden layer model from disk at {base_dir}/{self.filename}\")\n",
    "        self.model = torch.load(f\"{base_dir}/{self.filename}\")\n",
    "        \n",
    "    def train(self, X, y, base_dir=None):\n",
    "        device = self.__select_device()\n",
    "        lr = 0.01 # Learning rate\n",
    "        bs = 1000 # Batch size\n",
    "        droprate = self.droprate\n",
    "        hidden_neurons = self.hidden_neurons # Number of hidden layer neurons to use\n",
    "\n",
    "        print(f\"Preparing batches of training data\")\n",
    "        train_dataloader, test_dataloader = self.__get_dataloader(X, y)        \n",
    "        \n",
    "        model = OneLayerModelRobust(334, hidden_neurons, 1, bs, p=droprate).to(device)\n",
    "        \n",
    "        #optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9) # Stochastic gradient descent\n",
    "        #optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        criterion = nn.MSELoss(reduction='mean')\n",
    "                \n",
    "        print(f\"Starting training of neural network one hidden layer robust model with {hidden_neurons} hidden layer neurons and batch size {bs}\")\n",
    "        model, _ = self.__train(train_dataloader, test_dataloader, model, optimizer, criterion, device)\n",
    "        self.model = model\n",
    "        print(f\"Training complete\")\n",
    "        self.__save_model(base_dir)\n",
    "\n",
    "    def eval(self, X, y):\n",
    "        print(f\"Evaluating neural network one hidden layer robust model with {hidden_neurons} hidden layer neurons and batch size {bs}\")\n",
    "        _, s_r2 = self.__train(X, y)\n",
    "        return s_r2\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.drop([\"co2_total\"], axis=1)\n",
    "        device = self.__select_device()\n",
    "        X = self.__preprocess(X)\n",
    "        X = X.to_numpy(dtype='float32')\n",
    "        X = torch.tensor(X, dtype=torch.float)\n",
    "        X = X.to(device)        \n",
    "        y_pred = self.model(X)\n",
    "        y_pred = y_pred.detach().cpu().numpy().flatten().tolist()\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU!\n",
      "Preparing batches of training data\n",
      "Starting training of neural network one hidden layer robust model with 1024 hidden layer neurons and batch size 1000\n",
      "Epoch Train loss   Valid loss   Train RMSE Train R2  Test RMSE Test R2  \n",
      "1     169.60 173.75 12.94 0.78 13.07 0.77\n",
      "2     163.42 167.60 12.72 0.79 12.88 0.78\n",
      "3     160.27 164.82 12.58 0.79 12.75 0.79\n",
      "4     152.84 158.06 12.29 0.80 12.50 0.79\n",
      "5     148.98 154.39 12.14 0.80 12.35 0.80\n",
      "6     156.60 162.12 12.44 0.79 12.65 0.79\n",
      "7     147.44 153.88 12.07 0.81 12.32 0.80\n",
      "8     153.01 160.21 12.31 0.80 12.58 0.79\n",
      "9     142.36 148.80 11.87 0.81 12.12 0.81\n",
      "10    148.77 157.46 12.12 0.80 12.47 0.79\n",
      "11    151.52 160.49 12.24 0.80 12.58 0.79\n",
      "12    153.18 162.94 12.31 0.80 12.68 0.79\n",
      "13    151.66 162.36 12.24 0.80 12.65 0.79\n",
      "Neural network one hidden layer robust model trained in 9 epochs with stats RMSE = 12.11983871459961, R2 = 0.8061007474138568\n",
      "Training complete\n",
      "Saving neural network one hidden layer model to disk at ../mnt_emission_data/neural_onelayer_robust-hidden_1024.model\n"
     ]
    }
   ],
   "source": [
    "#model = NeuralNetworkOneLayerFF()\n",
    "model = NeuralNetworkOneLayerFFRobust(hidden_neurons=1024, droprate=0.2)\n",
    "X, y = load_source_data(base_dir)\n",
    "\n",
    "#model.load(base_dir)\n",
    "\n",
    "model.train(X, y, base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading neural network one hidden layer model from disk at ../mnt_emission_data/neural_onelayer-hidden_1024.model\n",
      "Using GPU!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.809248924255371,\n",
       " 1.1920044422149658,\n",
       " 18.669601440429688,\n",
       " 0.6584957838058472,\n",
       " 0.6584957838058472,\n",
       " 5.966665267944336,\n",
       " 13.39295482635498,\n",
       " 2.966787815093994,\n",
       " 29.39687728881836,\n",
       " 361.3407897949219,\n",
       " 0.6584957838058472,\n",
       " 2.627981185913086,\n",
       " 40.89984130859375,\n",
       " 39.8881721496582,\n",
       " 12.633627891540527,\n",
       " 14.36710262298584,\n",
       " 9.578902244567871,\n",
       " 20.312744140625,\n",
       " 29.310012817382812,\n",
       " 444.8851318359375,\n",
       " 50.13619613647461,\n",
       " 6.230341911315918,\n",
       " 2.8831300735473633,\n",
       " 56.619117736816406,\n",
       " 11.798055648803711,\n",
       " 24.753576278686523,\n",
       " 3.665116786956787,\n",
       " 18.04529571533203,\n",
       " 109.33907318115234,\n",
       " 14.763208389282227,\n",
       " 5.054282188415527,\n",
       " 0.6584957838058472,\n",
       " 5.673378944396973,\n",
       " 98.22073364257812,\n",
       " 67.57913208007812,\n",
       " 246.73191833496094,\n",
       " 21.412622451782227,\n",
       " 28.82978057861328,\n",
       " 2.031874656677246,\n",
       " 31.91777801513672,\n",
       " 0.6584957838058472,\n",
       " 72.1407241821289,\n",
       " 10.665579795837402,\n",
       " 3.2881951332092285,\n",
       " 0.6584957838058472,\n",
       " 26.929546356201172,\n",
       " 1.498579740524292,\n",
       " 45.53480529785156,\n",
       " 6.885274887084961,\n",
       " 5.967734336853027,\n",
       " 1.3629372119903564,\n",
       " 11.57351303100586,\n",
       " 4.288057327270508,\n",
       " 62.86119079589844,\n",
       " 27.896997451782227,\n",
       " 0.6584957838058472,\n",
       " 10.765332221984863,\n",
       " 13.11925220489502,\n",
       " 20.834718704223633,\n",
       " 4.9484758377075195,\n",
       " 37.931793212890625,\n",
       " 141.83180236816406,\n",
       " 10.473146438598633,\n",
       " 34.62299346923828,\n",
       " 0.6584957838058472,\n",
       " 0.6584957838058472,\n",
       " 3.9379844665527344,\n",
       " 2.7032928466796875,\n",
       " 36.82101821899414,\n",
       " 1.1093616485595703,\n",
       " 71.85225677490234,\n",
       " 3.9394803047180176,\n",
       " 28.24429702758789,\n",
       " 13.492880821228027,\n",
       " 9.46394157409668,\n",
       " 4.051589488983154,\n",
       " 13.249670028686523,\n",
       " 32.607177734375,\n",
       " 13.461112976074219,\n",
       " 0.9958588480949402,\n",
       " 3.269918918609619,\n",
       " 1.3188495635986328,\n",
       " 0.6584957838058472,\n",
       " 107.21797943115234,\n",
       " 2.6822590827941895,\n",
       " 0.6584957838058472,\n",
       " 93.24701690673828,\n",
       " 134.9573974609375,\n",
       " 0.6584957838058472,\n",
       " 5.583194732666016,\n",
       " 1.3414674997329712,\n",
       " 1.8808934688568115,\n",
       " 1.7575615644454956,\n",
       " 6.079160213470459,\n",
       " 1.860762357711792,\n",
       " 3.192986488342285,\n",
       " 28.862699508666992,\n",
       " 10.789677619934082,\n",
       " 3.100335121154785,\n",
       " 1.240450143814087]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = NeuralNetworkOneLayerFFRobust(hidden_neurons=1024)\n",
    "nn_model.load(base_dir)\n",
    "csv_file = \"../testdata/test.csv\"\n",
    "X = pd.read_csv(csv_file)\n",
    "pred = nn_model.predict(X)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
