{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data using pandas groupings for weight imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm  # for following progress\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textile-v1.0.0-1.csv textile-v1.0.0-3.csv textile-v1.0.0-5.csv\n",
      "textile-v1.0.0-2.csv textile-v1.0.0-4.csv\n"
     ]
    }
   ],
   "source": [
    "# Local data directory\n",
    "path = './tdata/'\n",
    "!ls  tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source_data(path):\n",
    "    \"\"\"\n",
    "    Read and concatenate the source data from the csv files to a pandas dataframe in local folder\n",
    "    \"\"\"\n",
    "    print('Starting to open data from csv-files')\n",
    "    content = sorted(filter(lambda x: x.endswith(\".csv\"), os.listdir(path)))\n",
    "    print('Data in content, starting to concatenate data')\n",
    "    df = pd.concat((pd.read_csv(f) for f in content))\n",
    "    print('Data loaded to pandas dataframe')\n",
    "\n",
    "    df = df[~df['weight'].isna()]\n",
    "    print('Rows with no weight value dropped')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mean_groups(df):\n",
    "    \"\"\"\n",
    "    Create different kind of dataframe groupings for estimating weights with the mean values of the groups\n",
    "    \"\"\"\n",
    "    \n",
    "    #****** Groups for all categorical features size, fabric type or both missing ****************#\n",
    "    # Mean for groups with all categorical features\n",
    "    togroup = ['category-1', 'category-2', 'category-3', 'fabric_type', 'gender', 'season', 'size']\n",
    "    w_groups = df.groupby(togroup, dropna = False)[\"weight\"].mean().reset_index()\n",
    "    #print(w_groups.sample(2))\n",
    "\n",
    "    # .. without size feature\n",
    "    w_groups_nsi = df.groupby(['category-1', 'category-2', 'category-3', 'fabric_type', 'gender', 'season'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_nsi.insert(6,'size',np.nan)\n",
    "    #print(w_groups_nsi.sample(2))\n",
    "    \n",
    "    # .. without fabric type feature\n",
    "    w_groups_nft = df.groupby(['category-1', 'category-2', 'category-3', 'gender', 'season', 'size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_nft.insert(3,'fabric_type',np.nan)\n",
    "    #print(w_groups_nft.sample())\n",
    "    \n",
    "    # ...without fabric type and size\n",
    "    w_groups_nftsi = df.groupby(['category-1', 'category-2', 'category-3', 'gender', 'season'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_nftsi.insert(3,'fabric_type',np.nan)\n",
    "    w_groups_nftsi.insert(6,'size',np.nan)\n",
    "    #print(w_groups_nftsi.sample(2))\n",
    "    \n",
    "    # .. without season feature\n",
    "    w_groups_nse = df.groupby(['category-1', 'category-2', 'category-3', 'fabric_type', 'gender', 'size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_nse.insert(5,'season',np.nan)\n",
    "    #print(w_groups_nse.sample(2))\n",
    "    \n",
    "    # .. without season and fabric type\n",
    "    w_groups_nseft = df.groupby(['category-1', 'category-2', 'category-3', 'gender', 'size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_nseft.insert(3,'fabric_type',np.nan)\n",
    "    w_groups_nseft.insert(5,'season',np.nan)\n",
    "    #print(w_groups_nseft.sample(2))\n",
    "    \n",
    "    \n",
    "    # Concatenate dataframes with all categories and with certain attribute missing \n",
    "    w_groups_a = pd.concat([w_groups, w_groups_nsi, w_groups_nft, w_groups_nftsi, w_groups_nse, w_groups_nseft])\n",
    "    print(w_groups_a.sample(5))\n",
    "    #*********************************************************************************************#\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #*****************    Groups for category-1, -2, -3 and size      ****************************#\n",
    "    # With all the features present\n",
    "    w_groups_cat123si = df.groupby(['category-1','category-2','category-3','size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    print(w_groups_cat123si.sample(2))\n",
    "    \n",
    "    # With size missing\n",
    "    w_groups_cat123 = df.groupby(['category-1','category-2','category-3'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat123.insert(3,'size',np.nan)\n",
    "    print(w_groups_cat123.sample(2))\n",
    "    \n",
    "    # With category-3 missing\n",
    "    w_groups_cat12si = df.groupby(['category-2','category-3','size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat12si.insert(0,'category-1',np.nan)\n",
    "    print(w_groups_cat12si.sample(2))\n",
    "    \n",
    "    # With category-2 missing\n",
    "    w_groups_cat13si = df.groupby(['category-1','category-3','size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat13si.insert(1,'category-2',np.nan)\n",
    "    print(w_groups_cat13si.sample(2))\n",
    "    \n",
    "    # With category-1 missing\n",
    "    w_groups_cat23si = df.groupby(['category-2','category-3','size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat23si.insert(0,'category-1',np.nan)\n",
    "    print(w_groups_cat23si.sample(2))\n",
    "    \n",
    "    # With category-1 and -2 missing\n",
    "    w_groups_cat3si = df.groupby(['category-3','size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat3si.insert(0,'category-1',np.nan)\n",
    "    w_groups_cat3si.insert(1,'category-2',np.nan)\n",
    "    print(w_groups_cat3si.sample(2))\n",
    "    \n",
    "    # With category-1 and -3 missing\n",
    "    w_groups_cat2si = df.groupby(['category-2','size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat2si.insert(0,'category-1',np.nan)\n",
    "    w_groups_cat2si.insert(2,'category-3',np.nan)\n",
    "    print(w_groups_cat2si.sample(2))\n",
    "    \n",
    "    # With category-2 and -3 missing\n",
    "    w_groups_cat1si = df.groupby(['category-1','size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat1si.insert(1,'category-2',np.nan)\n",
    "    w_groups_cat1si.insert(2,'category-3',np.nan)\n",
    "    print(w_groups_cat1si.sample(2))\n",
    "    \n",
    "    # With category-2, -3 and size missing\n",
    "    w_groups_cat1 = df.groupby(['category-1'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat1.insert(1,'category-2',np.nan)\n",
    "    w_groups_cat1.insert(2,'category-3',np.nan)\n",
    "    w_groups_cat1.insert(3,'size',np.nan)\n",
    "    print(w_groups_cat1.sample(2))\n",
    "    \n",
    "    # With category-1, -3 and size missing\n",
    "    w_groups_cat2 = df.groupby(['category-2'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat2.insert(0,'category-1',np.nan)\n",
    "    w_groups_cat2.insert(2,'category-3',np.nan)\n",
    "    w_groups_cat2.insert(3,'size',np.nan)\n",
    "    print(w_groups_cat2.sample(2))\n",
    "    \n",
    "    # With category-1, -2 and size missing\n",
    "    w_groups_cat3 = df.groupby(['category-3'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_cat3.insert(0,'category-1',np.nan)\n",
    "    w_groups_cat3.insert(1,'category-2',np.nan)\n",
    "    w_groups_cat3.insert(3,'size',np.nan)\n",
    "    print(w_groups_cat3.sample(2))\n",
    "    \n",
    "    # With category-1, -2 and -3 missing\n",
    "    w_groups_si = df.groupby(['size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "    w_groups_si.insert(0,'category-1',np.nan)\n",
    "    w_groups_si.insert(1,'category-2',np.nan)\n",
    "    w_groups_si.insert(2,'category-3',np.nan)\n",
    "    print(w_groups_si.sample(2))\n",
    "    \n",
    "    # Concatenate dataframes with category1, -2, -3 with a variety of missing values\n",
    "    l_wgroups = [w_groups_cat123si,w_groups_cat123,w_groups_cat12si,w_groups_cat13si,w_groups_cat23si,w_groups_cat1si,\n",
    "             w_groups_cat2si, w_groups_cat3si, w_groups_cat1,w_groups_cat2,w_groups_cat3,w_groups_si]\n",
    "    wg_cat123sia = pd.concat(l_wgroups)\n",
    "    print(wg_cat123sia.sample(5))\n",
    "    \n",
    "    return w_groups_a, wg_cat123sia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_weight(w_groups_a, wg_cat123sia, cat1= None, cat2 = None, cat3 = None, ft = None, g = None, se = None, si = None):\n",
    "    \"\"\"\n",
    "     Find based on categorical values mean weight from the given dataframes with respective mean values\n",
    "    \"\"\"\n",
    "    value = -5\n",
    "    \n",
    "    value = w_groups_a[((w_groups_a['category-1']==cat1) | (w_groups_a['category-1'].isnull())) &\n",
    "                     ((w_groups_a['category-2']==cat2) | (w_groups_a['category-2'].isnull())) &\n",
    "                     ((w_groups_a['category-3']==cat3) | (w_groups_a['category-3'].isnull())) &\n",
    "                     ((w_groups_a['fabric_type']==ft) | (w_groups_a['fabric_type'].isnull())) & \n",
    "                     ((w_groups_a['gender'] == g) | (w_groups_a['gender'].isnull()))  & \n",
    "                     ((w_groups_a['season'] == se) | (w_groups_a['season'].isnull())) & \n",
    "                     ((w_groups_a['size']==si) | (w_groups_a['size'].isnull()))]['weight']\n",
    "    if len(value) == 0:\n",
    "        value = wg_cat123sia[((wg_cat123sia['category-1']==cat1) | (wg_cat123sia['category-1'].isnull())) &\n",
    "                     ((wg_cat123sia['category-2']==cat2) | (wg_cat123sia['category-2'].isnull())) &\n",
    "                     ((wg_cat123sia['category-3']==cat3) | (wg_cat123sia['category-3'].isnull())) &\n",
    "                     ((wg_cat123sia['size']==si) | (wg_cat123sia['size'].isnull()))]['weight']\n",
    "    if len(value) == 0:\n",
    "        value = -1\n",
    "    else:\n",
    "        value= value.to_numpy()[0]\n",
    "    return float(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textile-v1.0.0-1.csv textile-v1.0.0-3.csv textile-v1.0.0-5.csv\n",
      "textile-v1.0.0-2.csv textile-v1.0.0-4.csv\n"
     ]
    }
   ],
   "source": [
    "# Local data directory\n",
    "path = './tdata/'\n",
    "!ls  tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to open data from csv-files\n",
      "Data in content, starting to concatenate data\n",
      "Data loaded to pandas dataframe\n",
      "Rows with no weight value dropped\n"
     ]
    }
   ],
   "source": [
    "df = load_source_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       category-1 category-2 category-3 fabric_type gender season size  \\\n",
      "9449   womenswear   clothing    T-shirt         NaN      W    NaN  XXL   \n",
      "4439     clothing       suit   trousers         NaN      K    WIN  XXL   \n",
      "11494    kidswear  outerwear      coats           K      Y    SUM   XS   \n",
      "1701     kidswear   clothing   overalls           K      B    MID  NaN   \n",
      "8108     kidswear   thermals   knitwear         NaN      B    WIN    S   \n",
      "\n",
      "         weight  \n",
      "9449   0.271415  \n",
      "4439   1.612563  \n",
      "11494  0.928373  \n",
      "1701   0.338857  \n",
      "8108   0.804363  \n",
      "     category-1 category-2 category-3 size    weight\n",
      "1020   menswear    costume     jacket    L  1.113863\n",
      "303    clothing  outerwear     gloves   XL  0.180292\n",
      "   category-1  category-2 category-3  size    weight\n",
      "28   clothing     costume      coats   NaN  2.077326\n",
      "55   clothing  sportswear      coats   NaN  2.068762\n",
      "     category-1 category-2 category-3 size    weight\n",
      "57          NaN   clothing     jacket   XL  1.047681\n",
      "217         NaN       home     pillow    M  0.133107\n",
      "      category-1  category-2 category-3 size    weight\n",
      "1006  womenswear         NaN      towel   XS  0.533397\n",
      "216     clothing         NaN     pyjama    L  0.437446\n",
      "     category-1 category-2 category-3 size    weight\n",
      "174         NaN   headgear        cap    L  0.102681\n",
      "434         NaN    uniform    costume    S  0.618383\n",
      "     category-1  category-2 category-3 size    weight\n",
      "144         NaN         NaN   knitwear    L  0.762825\n",
      "66          NaN         NaN    curtain    L  0.669991\n",
      "    category-1         category-2  category-3 size    weight\n",
      "88         NaN               suit         NaN   XS  0.597239\n",
      "62         NaN  men-undergarments         NaN    S  0.103574\n",
      "   category-1  category-2  category-3 size    weight\n",
      "21   kidswear         NaN         NaN   XL  0.477179\n",
      "9    clothing         NaN         NaN   XL  0.560073\n",
      "  category-1  category-2  category-3  size    weight\n",
      "4   menswear         NaN         NaN   NaN  0.558268\n",
      "0       baby         NaN         NaN   NaN  0.335350\n",
      "    category-1 category-2  category-3  size    weight\n",
      "16         NaN   thermals         NaN   NaN  0.390538\n",
      "2          NaN  beachwear         NaN   NaN  0.191620\n",
      "    category-1  category-2 category-3  size    weight\n",
      "42         NaN         NaN     tights   NaN  0.325769\n",
      "2          NaN         NaN      bikin   NaN  0.120918\n",
      "   category-1  category-2  category-3 size    weight\n",
      "2         NaN         NaN         NaN    S  0.490224\n",
      "0         NaN         NaN         NaN    L  0.539433\n",
      "      category-1 category-2   category-3 size    weight\n",
      "83           NaN   clothing     overalls  XXL  0.538304\n",
      "943     menswear   clothing       jacket    M  1.055560\n",
      "473     clothing    uniform       gloves  XXL  0.186487\n",
      "1398  womenswear   clothing          top    L  0.092017\n",
      "126     clothing        NaN  fancy-dress    L  0.533724\n"
     ]
    }
   ],
   "source": [
    "df1, df2 = prepare_mean_groups(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = 'clothing'\n",
    "cat2 = 'costume'\n",
    "cat3 = 'trousers'\n",
    "si = 'L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066842735656965"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_mean_weight(df1, df2, cat2=cat2, cat3 = cat3, si = si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753975013627198"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_mean_weight(df1, df2, cat3 = cat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5394330362988069"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_mean_weight(df1, df2, si = si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_groups_si = df.groupby(['size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "w_groups_si.insert(0,'category-1',np.nan)\n",
    "w_groups_si.insert(1,'category-2',np.nan)\n",
    "w_groups_si.insert(2,'category-3',np.nan)\n",
    "w_groups_si.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_groups_cat3si = df.groupby(['category-3','size'], dropna = False)[\"weight\"].mean().reset_index()\n",
    "w_groups_cat3si.insert(0,'category-1',np.nan)\n",
    "w_groups_cat3si.insert(1,'category-2',np.nan)\n",
    "w_groups_cat3si.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_wgroups = [w_groups_cat123si,w_groups_cat123,w_groups_cat12si,w_groups_cat13si,w_groups_cat23si,w_groups_cat1si,\n",
    "             w_groups_cat2si, w_groups_cat3si, w_groups_cat1,w_groups_cat2,w_groups_cat3,w_groups_si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_cat123sia = pd.concat(l_wgroups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
